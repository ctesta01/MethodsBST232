<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Methods (BST 232) Notes - 11&nbsp; Week 10</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../week9/week9.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-title">Week 10</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Methods (BST 232) Notes</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Methods (BST 232) Notes</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week1/week1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 1</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week2/week2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 2</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week3/week3.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 3</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week4/week4.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 4</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week5/week5.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 5</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week6/week6.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 6</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week7/week7.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 7</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week8/week8.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 8</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week9/week9.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Week 9</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../week10/week10.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Week 10</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#generalized-linear-models" id="toc-generalized-linear-models" class="nav-link active" data-scroll-target="#generalized-linear-models">Generalized Linear Models</a>
  <ul class="collapse">
  <li><a href="#exponential-family" id="toc-exponential-family" class="nav-link" data-scroll-target="#exponential-family">Exponential Family</a>
  <ul class="collapse">
  <li><a href="#bernoulli-in-the-exponential-notation" id="toc-bernoulli-in-the-exponential-notation" class="nav-link" data-scroll-target="#bernoulli-in-the-exponential-notation">Bernoulli in the Exponential Notation</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-title">Week 10</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>So far we’ve done one-sample tests for proportions, two-sample tests for proportions, contingency tables, and we’ve really allowed for at most looking at one binary outcome and one binary covariate.</p>
<p>Now we ask what if we want to build a regression model to look at a binary outcome with multiple predictors, or adjusted for multiple other covariates.</p>
<p>We’ll work with the following lung surgery example:</p>
<p>Is there an association between time spent in the operating room and post-surgical outcomes?</p>
<p>We could choose from a number of possible outcome variables, including: * Hospital stay of &gt;7 days * Number of major complications during the hospital stay</p>
<p>The first outcome is binary (<span class="math inline">\(Y \in \{ 0, 1 \}\)</span>) and the second is a count variable (<span class="math inline">\(Y \in \{ 0, 1, 2, ... \}\)</span>).</p>
<p>The scientific goal might be to characterize the relationship between such an outcome and a <span class="math inline">\(p\)</span>-vector of covariatets, <span class="math inline">\(\mathbf{x}\)</span>.</p>
<p>Why can’t we just use linear regression? We could just specify a mean model where <span class="math inline">\(\mathbb E[Y_i | \mathbf{x}_i] = \mathbf{x}_i' \beta\)</span> and estimate <span class="math inline">\(\beta\)</span> via OLS and perform inference via the CLT (which tells us that <span class="math inline">\(\hat \beta \stackrel{\cdot}{\sim} \mathcal N\)</span>?</p>
<p>OLS has nice properties under mild conditions: * if the mean model is correctly specified, <span class="math inline">\(\hat \beta_{OLS}\)</span> is unbiased * OLS is generally robust to the distribution of the error terms * OLS is BLUE if the error terms are homoscedastic.</p>
<p>The first issue one might run into is heteroscedasticity. If <span class="math inline">\(Y_i\)</span> is binary, then we know that it has to be Bernoulli distributed, such that under the mean model specification,</p>
<p><span class="math display">\[Y_i | \mathbf{x}_i \sim \text{Bernoulli}(\mu_i), \quad \text{ where } \mu = P(Y = 1) = \mathbb E(Y)\]</span> <span class="math display">\[ \mu_i = \mathbb E[Y_i | \mathbf{x}_i = \mathbf{x}_i' \beta]. \]</span></p>
<p>For the Bernoulli distribution, there is an implicit mean-variance relationship:</p>
<p><span class="math display">\[\text{Var}[Y_i | \mathbf{x}_i] = \mu_i (1 - \mu_i)\]</span></p>
<p>as long as <span class="math inline">\(\mu_i \neq \mu \forall i\)</span>, study units will be heteroscedastic (i.e., have non-constant variance).</p>
<p>As we’ve seen, heteroscedasticity isn’t a problem that goes away with large samples. It doesn’t go away with the central limit theorem.</p>
<p>Ignoring hteroscedasticity results in invalid inference, but we’ve seen three ways to remedy the situation: * Transform the response variable * Use OLS and base inference on a valid standard error * Use generalized least squares (GLS)</p>
<p>GLS can be a good option in discrete cases that is often under-appreciated, but it does have some limitations that lead many away from using it.</p>
<p>Recall <span class="math display">\[\hat \beta_{GLS} = (\mathbf{X}'\mathbf{\Sigma}^{-1}\mathbf{X})^{-1} \mathbf{X}' \mathbf{\Sigma}^{-1} \mathbf{y}\]</span> where if <span class="math inline">\(\text{Var}(Y_i | \mathbf{x}_i) = \mu_i (1-\mu_i)\)</span>, then</p>
<p><span class="math display">\[\Sigma = \text{diag}(\mu_1(1-\mu_1), ..., \mu_N(1-\mu_N))\]</span></p>
<p>and <span class="math inline">\(\hat \beta_{GLS}\)</span> is BLUE.</p>
<p>Recall that in the typical OLS setting, the <span class="math inline">\(\Sigma\)</span> matrix is given by <span class="math inline">\(\text{diag}(\sigma_1^2, ..., \sigma_N^2)\)</span>, but here we aren’t in a setting where <span class="math inline">\(Y = X \beta + \varepsilon\)</span> and <span class="math inline">\(\text{Var}(\varepsilon) = \sigma^2\)</span>, but instead we’re in this setting where the variance of <span class="math inline">\(Y\)</span> is informed by the Bernoulli distribution’s variance conditional on how the covariates inform the mean.</p>
<p>Recall that for uncorrelated data <span class="math inline">\(\hat \beta_{GLS}\)</span> is the maximizer of a weighted least squares criterion, i.e., <span class="math inline">\(\sum{i=1}^n w_i (y_i - x_i' \beta)^2\)</span> where <span class="math inline">\(w_i = (\text{Var}(Y_i | x_i))^{-1}\)</span>.</p>
<p>Thus we solve for <span class="math inline">\(\beta\)</span> in</p>
<p><span class="math display">\[ 0 = \frac{\partial}{\partial \beta } \sum{i=1}^n w_i (y_i - x_i' \beta)^2\]</span></p>
<p><span class="math display">\[ 0 = \sum_{i=1}^n x_i w_i (y_i x_i' \beta)\]</span></p>
<p>So when <span class="math inline">\(w_i = (\mu_i (1- \mu_i))^{-1}\)</span>, the weighted least squared equations are <span class="math display">\[0 = \sum_{i=1}^n \frac{x_i}{\mu_i ( 1- \mu_i)} (y_i - \mu_i).\]</span></p>
<p>In practice, we use the IRLS algorithm to estimate <span class="math inline">\(\hat \beta_{GLS}\)</span>.</p>
<p><span class="math inline">\(\hat \beta_{GLS}\)</span> is also the MLE when <span class="math inline">\(Y_i \sim \text{Bernoulli}(\mu_i)\)</span>. The likelihood and log-likelihood are given by</p>
<p><span class="math display">\[\mathcal L(\beta | y) = \prod_{i=1}^n \mu_i^{y_i} (1-\mu_i)^{1-y_i},\]</span> <span class="math display">\[\ell(\beta | y) = \sum_{i=1}^n [y_i \log (\mu_i) + (1-y_i) \log (1-\mu_i)].\]</span></p>
<p>To get the MLE, we take derivatives, set them equal to zero and solve. Following the algebra trail, we find that</p>
<p><span class="math display">\[\frac{\partial}{\partial \beta} \ell (\beta | y ) = \sum_{i=1}^n \frac{x_i}{\mu_i (1-\mu_i)} (y_i - \mu_i) \stackrel{set}{=} 0.\]</span></p>
<p>Thus the derivative of the log likelihood is equivalent to the weighted least squares equations, so <span class="math inline">\(\hat \beta_{GLS}\)</span> is the MLE.</p>
<p>Often it’s fine to use this approach, but we’ll see some shortcomings soon.</p>
<p>GLS can accomodate heteroscedasticity for binary outcomes. If the model is correctly specified, GLS is optimal.</p>
<p>However, when modeling binary or count response data, the linear regression model doesn’t respect the fact that the outcome is bounded. The functional that is being modeled is bounded:</p>
<ul>
<li>in binary outcome settings: <span class="math inline">\(\mathbb E[Y_i | x_i] \in (0,1)\)</span></li>
<li>in count outcome settings: <span class="math inline">\(\mathbb E[Y_i | x_i] \in (0,\infty)\)</span>,</li>
</ul>
<p>but our current specifications of the mean model doesn’t impose any restrictions and only assumes <span class="math inline">\(\mathbb E[Y_i|x_i] = x_i' \beta\)</span>. This means we could get predictions that are outside the region of appropriate outcomes.</p>
<p>Is this a big deal? Only sometimes. The GLS approach works quite well for modeling binary outcomes and the coefficients from linear models are quite interpretable. So it’s a trade-off between coefficient interpretability and this property about restricting predictions to the specified set of possible outcomes.</p>
<section id="generalized-linear-models" class="level1">
<h1>Generalized Linear Models</h1>
<p>Our goal is to develop statistical models to characterize the relationship between some response variable <span class="math inline">\(Y\)</span> and a vector of covariates <span class="math inline">\(x\)</span>.</p>
<p>Statistical models consist of two components:</p>
<ul>
<li>A systematic component</li>
<li>A random component</li>
</ul>
<p>When moving beyond linear regression analysis of continuous and response data, we need to be aware of two key challenges: * Sensible specification of the systematic component * Proper accounting of any implicit mean-variance relationships arising from the random component.</p>
<p><span class="vocab">Definition of a Generalized Linear Model</span></p>
<p>A <em>generalized linear model</em> (GLM) specifies a parametric statistical model for the conditional distribution of a response <span class="math inline">\(Y_i\)</span> given a <span class="math inline">\(p\)</span>-vector of covariates <span class="math inline">\(x_i\)</span>.</p>
<p>Consistes of three elements:</p>
<ol type="1">
<li>A probability distribution for the outcome, <span class="math inline">\(Y_i \sim f_{Y}(y)\)</span></li>
<li>A linear prediction equation, <span class="math inline">\(x_i' \beta\)</span></li>
<li>A link function, <span class="math inline">\(g(\cdot)\)</span>.</li>
</ol>
<p>The first of these elements is the random component, and elements 2 and 3 jointly specify the systematic component.</p>
<p>In practice, we see a wide range of response variables with a wide range of associated (possible) distributions</p>
<table class="table">
<thead>
<tr class="header">
<th>Response Type</th>
<th>Range</th>
<th>Possible Distribution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Continuous</td>
<td><span class="math inline">\((-\infty, \infty)\)</span></td>
<td><span class="math inline">\(\mathcal N(\mu, \sigma^2)\)</span></td>
</tr>
<tr class="even">
<td>Binary</td>
<td><span class="math inline">\(\{0, 1\}\)</span></td>
<td><span class="math inline">\(\text{Bernoulli}(\pi)\)</span></td>
</tr>
<tr class="odd">
<td>Polytomous</td>
<td><span class="math inline">\(\{1, ..., K \}\)</span></td>
<td><span class="math inline">\(\text{Multinomial}(\pi_k)\)</span></td>
</tr>
<tr class="even">
<td>Count</td>
<td><span class="math inline">\(\{0, 1, ..., n \}\)</span></td>
<td><span class="math inline">\(\text{Binomial}(n, \pi)\)</span></td>
</tr>
<tr class="odd">
<td>Count</td>
<td><span class="math inline">\(\{1, 2, ..., \}\)</span></td>
<td><span class="math inline">\(\text{Poisson}(\lambda)\)</span></td>
</tr>
<tr class="even">
<td>Positive</td>
<td><span class="math inline">\((0, \infty)\)</span></td>
<td><span class="math inline">\(\text{Gamma}(\alpha, \beta)\)</span></td>
</tr>
</tbody>
</table>
<p>For a given choice of probability distribution, a GLM specifies a model for the conditional mean:</p>
<p><span class="math display">\[ \mu_i = \mathbb E[Y_i | x_i] \]</span></p>
<p>How do we specify a reasonable model for <span class="math inline">\(\mu_i\)</span> while ensuring that we respect the appropriate range/scale of <span class="math inline">\(\mu_i\)</span>?</p>
<p>Achieved by constructing a linear predictor <span class="math inline">\(x_i' \beta\)</span> and relating it to <span class="math inline">\(\mu_i\)</span> via a link function <span class="math inline">\(g(\cdot)\)</span>:</p>
<p><span class="math display">\[g(\mu_i) = x_i' \beta.\]</span></p>
<p>We often specify <span class="math inline">\(g(\cdot)\)</span> such that <span class="math inline">\(g^{-1}(x_i' \beta) = \mu\)</span> respects the appropriate bounds on <span class="math inline">\(\mu_i\)</span>.</p>
<p>We’ll sometimes use the shorthand <span class="math inline">\(\eta_i = x_i' \beta\)</span>.</p>
<div class="cooltip">
<p>How is it that the regular linear model is a trivial GLM? Isn’t it the case that we only make distributional assumptions on <span class="math inline">\(\varepsilon\)</span> and not on <span class="math inline">\(Y\)</span>? Yes, but because a normal distribution plus a constant is still normally distributed (but this is not true for other distributions, e.g., a Binomial or Bernoulli distribution).</p>
<p>In the linear model we assume <span class="math inline">\(Y_i = X_i \beta + \epsilon_i\)</span>, so we could write <span class="math inline">\(Y \sim \mathcal N(X_i \beta, \sigma^2)\)</span> giving us the distributional assumption on <span class="math inline">\(Y\)</span>.</p>
<p>If we suppose that <span class="math inline">\(X_i \sim \text{Bernoulli}(\pi)\)</span>, we can’t model <span class="math inline">\(X_i \beta + \varepsilon_i\)</span> as another Bernoulli distribution where <span class="math inline">\(\varepsilon\)</span> is Bernoulli distributed.</p>
<p>This is why we’re going to have to write <span class="math inline">\(Y_i \sim f_Y\)</span> and <span class="math inline">\(g(\mu_i) = X_i \beta\)</span>.</p>
</div>
<section id="exponential-family" class="level2">
<h2 class="anchored" data-anchor-id="exponential-family">Exponential Family</h2>
<p>GLMs form a class of statistical models for response variables whose distribution belongs to the <em>exponential dispersion family</em></p>
<p>These are the family of distributions with a pdf/pmf of the form:</p>
<p><span class="math display">\[f_Y(y; \theta, \phi) = \exp \left\{ \frac{y \theta - b(\theta)}{a(\phi)} + c(y, \phi) \right\},\]</span></p>
<p>where <span class="math inline">\(\theta\)</span> is the <em>canonical parameter</em>, <span class="math inline">\(\phi\)</span> is the <em>dispersion parameter</em>, and <span class="math inline">\(b(\theta)\)</span> is the <em>cumulant function</em>.</p>
<p>We will see that <span class="math inline">\(\theta\)</span> is always a function of the conditional mean, <span class="math inline">\(\mu_i\)</span>.</p>
<p>Note that the <span class="math inline">\(c(y, \phi)\)</span> should not depend on <span class="math inline">\(\theta\)</span>.</p>
<section id="bernoulli-in-the-exponential-notation" class="level3">
<h3 class="anchored" data-anchor-id="bernoulli-in-the-exponential-notation">Bernoulli in the Exponential Notation</h3>
<p>Let <span class="math inline">\(Y \sim \text{Bernoulli}(\mu)\)</span>.</p>
<p>A common first step is to apply a convenient transformation that is equivalent to the identity function: <span class="math inline">\(\exp(\log(\cdot))\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
f_Y(y ; \mu ) &amp; = \mu^y (1- \mu)^{1-y} \\
&amp; = \exp \{ y \log(\mu) + (1-y) \log (1-\mu) \} \\
&amp; = \exp \left\{ y \log \left( \frac{\mu}{1-\mu} \right)  + \log(1-\mu) \right\}
\end{aligned}
\]</span></p>
<p>Let</p>
<p><span class="math display">\[
\begin{aligned}
\theta = \log\left( \frac{\mu}{1-\mu} \right) \quad \quad &amp; b(\theta) = \log (1 + \exp \{ \theta \}) \\
a(\phi) = 1 \quad \quad &amp; c(y, \phi) = 0
\end{aligned}
\]</span></p>
<p>Then <span class="math display">\[
\begin{aligned}
f_Y(y; \theta, \phi) &amp; = \exp \{ y \theta - \log (1 + \exp \{ \theta \} ) \} \\
&amp; = \exp \left\{ \frac{y \theta - b(\theta) }{a(\phi)} + c(y, \phi) \right\}.
\end{aligned}
\]</span></p>
<p>Many other common distributions are members of this faimly. The canonical parameter <span class="math inline">\(\theta\)</span> has key relationships with both <span class="math inline">\(\mathbb E(Y)\)</span> and <span class="math inline">\(\text{Var}(Y)\)</span>. Typically varies across study units since <span class="math inline">\(\mathbb E(Y_i) = \mu_i\)</span>. We also index <span class="math inline">\(\theta\)</span> by <span class="math inline">\(i\)</span>, as in <span class="math inline">\(\theta_i\)</span>.</p>
<p>The dispersion parameter <span class="math inline">\(\phi\)</span> has a key relationship with <span class="math inline">\(\text{Var}(Y)\)</span>. It may, but does not typically, vary across study units. Typically it is not unit-specific, so we just write <span class="math inline">\(\phi\)</span>. In some settings, we may have <span class="math inline">\(a(\cdot)\)</span> vary with <span class="math inline">\(i\)</span>, as in $<span class="math inline">\(a_i(\phi)\)</span>. E.g., <span class="math inline">\(a_i(\phi) = \phi / w_i\)</span> where <span class="math inline">\(w_i\)</span> is the prior weight.</p>
<p>When the dispersion parameter is known, some may say that this distribution is a member of the <em>natural exponential family</em>.</p>
<p>Consider the likelihood function for a single observation</p>
<p><span class="math display">\[\mathcal L(\theta_i, \phi ; y_i) = \exp \left\{ \frac{y_i \theta - b(\theta_i)}{a_i(\phi)} + c(y_i, \phi) \right\}.\]</span></p>
<p>The log-likelihood is</p>
<p><span class="math display">\[\ell(\theta_i, \phi; y_i) = \frac{y_i \theta_i - b(\theta_i)}{a_i(\phi)} + c(y_i, \phi).\]</span></p>
<p>The first partial derivative with respect to <span class="math inline">\(\theta_i\)</span> is the score function for <span class="math inline">\(\theta_i\)</span> and is given by</p>
<p><span class="math display">\[\frac{\partial}{\partial \theta_i} \ell (\theta_i, \phi; y_i) = U(\theta_i) = \frac{y_i - b'(\theta_i)}{a_i(\phi)}.\]</span></p>
<p>Note that we consider <span class="math inline">\(\frac{\partial}{\partial \theta_i} \ell (\theta_i, \phi; y_i)\)</span> for the purpose of showing properties of exponential families (not for doing estimation).</p>
<p>We know that (under some regularity conditions)</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb E[U(\theta_i)] &amp; = 0 \\
\text{Var}[U(\theta_i)] &amp; = \mathbb E[U(\theta_i)^2] = \mathbb E\left[ \frac{\partial U(\theta_i)}{\partial \theta_i} \right]
\end{aligned}
\]</span></p>
<p>We will use these properties to get expressions for <span class="math inline">\(\mathbb E(Y_i)\)</span> and <span class="math inline">\(\text{Var}(Y_i)\)</span> in terms of the exponential family parameters.</p>
<p>Since the score has mean zero,</p>
<p><span class="math display">\[\mathbb E(U(\theta_i)) = \mathbb E\left[ \frac{Y_i - b'(\theta_i)}{a_i(\phi)} \right] = 0 \]</span></p>
<p>and, consequently,</p>
<p><span class="math display">\[\mu_i = \mathbb E[Y_i] = b'(\theta_i).\]</span></p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../week9/week9.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Week 9</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>